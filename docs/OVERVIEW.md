# Overview

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BENCHMARK ORCHESTRATOR                    â”‚
â”‚                   src/runner/orchestrator.ts                  â”‚
â”‚  (CLI parsing, work queue generation, progress tracking)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TASK LOADER         â”‚          â”‚  WORK QUEUE          â”‚
â”‚  (src/loader/)       â”‚          â”‚  & CONCURRENCY       â”‚
â”‚  - Loads JSON tasks  â”‚          â”‚  - AsyncSemaphore    â”‚
â”‚  - Validates schema  â”‚          â”‚  - Shuffle with seed â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                               â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  WORK ITEM EXECUTION    â”‚
                   â”‚  (Per condition & rep)   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                       â–¼                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ AGENT       â”‚         â”‚EVALUATOR â”‚          â”‚ RESULT     â”‚
    â”‚ (src/runner/â”‚         â”‚(src/     â”‚          â”‚ STORE      â”‚
    â”‚ agent.ts)   â”‚         â”‚runner/)  â”‚          â”‚(src/runner/â”‚
    â”‚ - Runs      â”‚         â”‚- AST     â”‚          â”‚result-     â”‚
    â”‚   opencode  â”‚         â”‚  checks  â”‚          â”‚store.ts)   â”‚
    â”‚ - Extracts  â”‚         â”‚- Type    â”‚          â”‚- Stores    â”‚
    â”‚   files     â”‚         â”‚  check   â”‚          â”‚  JSON      â”‚
    â”‚ - Parses    â”‚         â”‚- Judge   â”‚          â”‚  results   â”‚
    â”‚   output    â”‚         â”‚  scoring â”‚          â”‚- Atomic    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  writes    â”‚
                                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  REPORTER            â”‚
                    â”‚ (src/runner/         â”‚
                    â”‚  reporter.ts)        â”‚
                    â”‚- Aggregates results  â”‚
                    â”‚- Computes metrics    â”‚
                    â”‚- Generates reports   â”‚
                    â”‚- Text + JSON output  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Directory Structure

```
nia-bench/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts                      # Entry point â†’ orchestrator
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”œâ”€â”€ task.ts                   # Task schema (Zod)
â”‚   â”‚   â””â”€â”€ reference.ts              # Reference solution types
â”‚   â”œâ”€â”€ loader/
â”‚   â”‚   â”œâ”€â”€ task-loader.ts            # Loads & validates task JSON files
â”‚   â”‚   â””â”€â”€ __tests__/
â”‚   â”œâ”€â”€ runner/                       # Core orchestration
â”‚   â”‚   â”œâ”€â”€ orchestrator.ts           # Main benchmark runner
â”‚   â”‚   â”œâ”€â”€ agent.ts                  # OpenCode agent executor
â”‚   â”‚   â”œâ”€â”€ evaluator.ts              # Evaluation (AST + type check + judge)
â”‚   â”‚   â”œâ”€â”€ reporter.ts               # Report generation & metrics
â”‚   â”‚   â”œâ”€â”€ result-store.ts           # Result persistence
â”‚   â”‚   â”œâ”€â”€ mcp_configs/              # OpenCode configuration files
â”‚   â”‚   â”‚   â”œâ”€â”€ nia.opencode.json
â”‚   â”‚   â”‚   â”œâ”€â”€ context7.opencode.json
â”‚   â”‚   â”‚   â””â”€â”€ baseline.opencode.json
â”‚   â”‚   â””â”€â”€ __tests__/
â”‚   â”œâ”€â”€ judge/                        # LLM-based evaluation
â”‚   â”‚   â”œâ”€â”€ hallucination-classifier.ts # Classifies failure types
â”‚   â”‚   â”œâ”€â”€ rubric-scorer.ts          # Scores against rubric
â”‚   â”‚   â”œâ”€â”€ prompt-template.ts        # Judge prompts
â”‚   â”‚   â”œâ”€â”€ openrouter-client.ts      # LLM API calls
â”‚   â”‚   â””â”€â”€ __tests__/
â”‚   â””â”€â”€ tests/                        # Automated code evaluation
â”‚       â”œâ”€â”€ ast-checker.ts            # AST validation
â”‚       â”œâ”€â”€ type-checker.ts           # TypeScript type checking
â”‚       â””â”€â”€ __tests__/
â”‚
â”œâ”€â”€ tasks/                            # Task definitions (40 JSON files)
â”‚   â”œâ”€â”€ bleeding_edge/                # Category A: Latest features
â”‚   â”‚   â”œâ”€â”€ nextjs-16-*.json          # 3 Next.js 16 tasks
â”‚   â”‚   â”œâ”€â”€ react-19-*.json           # 3 React 19 tasks
â”‚   â”‚   â”œâ”€â”€ ai-sdk-5-*.json           # 3 AI SDK 5 tasks
â”‚   â”‚   â”œâ”€â”€ trpc-11-*.json            # 3 tRPC 11 tasks
â”‚   â”‚   â””â”€â”€ zod-4-*.json              # 2 Zod 4 tasks
â”‚   â”œâ”€â”€ version_locked_write/         # Category B1: Write for specific version
â”‚   â”‚   â”œâ”€â”€ nextjs-13-*.json
â”‚   â”‚   â”œâ”€â”€ nextjs-14-*.json
â”‚   â”‚   â”œâ”€â”€ nextjs-15-*.json
â”‚   â”‚   â”œâ”€â”€ react-17-*.json
â”‚   â”‚   â”œâ”€â”€ react-18-*.json
â”‚   â”‚   â”œâ”€â”€ ai-sdk-3-*.json
â”‚   â”‚   â”œâ”€â”€ trpc-10-*.json
â”‚   â”‚   â””â”€â”€ zod-3-*.json
â”‚   â””â”€â”€ version_locked_audit/         # Category B2: Audit code for version
â”‚       â””â”€â”€ (12 audit tasks)
â”‚
â”œâ”€â”€ results/                          # Output directory (created at runtime)
â”‚   â””â”€â”€ {timestamp}/
â”‚       â”œâ”€â”€ run-meta.json             # Run metadata
â”‚       â”œâ”€â”€ report.json               # Structured report
â”‚       â”œâ”€â”€ report.txt                # Human-readable report
â”‚       â””â”€â”€ {taskId}/
â”‚           â””â”€â”€ {condition}/
â”‚               â””â”€â”€ run-{index}.json  # Individual result files
â”‚
â”œâ”€â”€ typecheck-envs/                   # TypeScript environments for version testing
â”‚   â”œâ”€â”€ react-17/
â”‚   â”œâ”€â”€ react-18/
â”‚   â”œâ”€â”€ react-19/
â”‚   â”œâ”€â”€ next-13/ through next-16/
â”‚   â”œâ”€â”€ zod-3/
â”‚   â”œâ”€â”€ zod-4/
â”‚   â”œâ”€â”€ ai-sdk-3/ through ai-sdk-5/
â”‚   â””â”€â”€ trpc-10/
â”‚       trpc-11/
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ BENCHMARK.md                  # Detailed specification (1500+ lines)
â”‚
â””â”€â”€ scripts/                          # Validation scripts
    â”œâ”€â”€ validate-bleeding-edge-tasks.ts
    â”œâ”€â”€ validate-version-locked-write-tasks.ts
    â”œâ”€â”€ validate-version-locked-audit-tasks.ts
    â””â”€â”€ validate-pilot-tasks.ts
```

---

## ğŸ”„ Complete Workflow

### Phase 1: Initialization & Configuration

```
User runs: bun run src/index.ts [--options]
    â”‚
    â””â”€â†’ parseCliArgs()
        â”‚
        â””â”€â†’ Configuration created with:
            - Tasks directory
            - Output directory
            - Parallelization level (1-N workers)
            - Repetitions per task/condition (default: 3)
            - Random seed for reproducibility
            - Model override (optional)
```

### Phase 2: Task Loading & Validation

```
loadTasks(tasksDir, filters)
    â”‚
    â”œâ”€â†’ Scan task JSON files (37 total)
    â”‚
    â”œâ”€â†’ Validate each task with TaskSchema (Zod)
    â”‚   - Check required fields: id, category, library, prompt, etc.
    â”‚   - Validate AST checks, rubric criteria
    â”‚   - Validate test specifications
    â”‚
    â””â”€â†’ Return Task[] and errors[]
        (Tasks marked with "status: 'error'" are filtered out)
```

**Task Structure:**

```typescript
interface Task {
  id: string; // "nextjs-16-proxy-ts"
  category: "bleeding_edge" | "version_locked_write" | "version_locked_audit";
  library: "next" | "react" | "ai" | "trpc" | "zod";
  target_version: string; // "16.0.0"
  prompt: string; // The task prompt
  reference_solution: string; // Canonical correct code
  test_spec: {
    ast_checks: AstCheck[]; // Automated validation rules
    type_check: boolean; // Enable TypeScript checking
  };
  rubric: {
    criteria: RubricCriterion[]; // Judge evaluation criteria
  };
  common_hallucinations: string[]; // Known failure modes
}
```

### Phase 3: Work Queue Generation

```
generateWorkQueue(taskIds, conditions, reps)
    â”‚
    â”œâ”€â†’ Create items for each combination:
    â”‚   (taskId, condition, repIndex)
    â”‚
    â””â”€â†’ Example: 40 tasks Ã— 3 conditions Ã— 3 reps = 360 work items

    Shuffle queue with seeded RNG for reproducibility

    Example item:
    {
      taskId: "nextjs-16-proxy-ts",
      condition: "nia",
      repIndex: 0
    }
```

### Phase 4: Concurrent Execution

```
AsyncSemaphore(maxParallel=N) controls concurrency

For each work item:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ AGENT EXECUTION (agent.ts)                 â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ 1. Create temp working directory            â”‚
  â”‚ 2. Set up opencode environment              â”‚
  â”‚    - Select config based on condition       â”‚
  â”‚    - Add baseline/context7/nia MCP configs  â”‚
  â”‚ 3. Build prompt:                            â”‚
  â”‚    task.prompt + opencode system prompt     â”‚
  â”‚ 4. Execute opencode CLI:                    â”‚
  â”‚    opencode --model X --config Y <<< promptâ”‚
  â”‚ 5. Stream NDJSON output, parse events       â”‚
  â”‚ 6. Extract code files from streaming output â”‚
  â”‚    (Parse "tool_output" events)             â”‚
  â”‚ 7. Return AgentResult {                     â”‚
  â”‚      taskId, condition, runIndex,           â”‚
  â”‚      extractedFiles, rawOutput, exitCode... â”‚
  â”‚    }                                        â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ EVALUATION (evaluator.ts)                  â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚                                             â”‚
  â”‚ 1. AST CHECK PHASE (runAstChecks)          â”‚
  â”‚    - Parse extracted code with ts-morph    â”‚
  â”‚    - Execute all test_spec.ast_checks      â”‚
  â”‚    - Check: imports, exports, functions,   â”‚
  â”‚      async/await, directives, etc.         â”‚
  â”‚    - Result: AstCheckResult[] with pass/fail
  â”‚                                             â”‚
  â”‚ 2. TYPE CHECK PHASE (optional)             â”‚
  â”‚    - Use appropriate typecheck-env version â”‚
  â”‚    - Run tsc --noEmit on extracted code    â”‚
  â”‚    - Detect version-specific type errors   â”‚
  â”‚    - Result: TypeCheckResult (pass/fail)   â”‚
  â”‚                                             â”‚
  â”‚ 3. HALLUCINATION CLASSIFICATION            â”‚
  â”‚    - Map AST failures to hallucination typeâ”‚
  â”‚    - Types: invented_method, wrong_param,  â”‚
  â”‚      outdated_api, future_api, etc.        â”‚
  â”‚    - Result: HallucinationResult           â”‚
  â”‚                                             â”‚
  â”‚ 4. LLM JUDGE SCORING (if !skipJudge)       â”‚
  â”‚    - Build judge prompt with:              â”‚
  â”‚      * Task description                    â”‚
  â”‚      * Reference solution                  â”‚
  â”‚      * Agent-generated code                â”‚
  â”‚      * Rubric criteria                     â”‚
  â”‚    - Call OpenRouter API (Claude Opus)     â”‚
  â”‚    - Parse structured JSON response        â”‚
  â”‚    - Score each rubric criterion (0-1)     â”‚
  â”‚    - Result: JudgeResult with criterion    â”‚
  â”‚      scores and explanations               â”‚
  â”‚                                             â”‚
  â”‚ 5. FINAL SCORE CALCULATION                 â”‚
  â”‚    finalScore = 0.6 Ã— testScore            â”‚
  â”‚               + 0.4 Ã— judgeScore           â”‚
  â”‚    where testScore = % of AST checks passed
  â”‚                                             â”‚
  â”‚ 6. Return EvaluationResult {                â”‚
  â”‚      taskId, condition, runIndex,          â”‚
  â”‚      testScore, judgeScore, finalScore,    â”‚
  â”‚      astResults[], typeCheckResult,        â”‚
  â”‚      judgeResult, hallucinations...        â”‚
  â”‚    }                                        â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ RESULT PERSISTENCE (result-store.ts)       â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ Write to: results/{runDir}/{taskId}/       â”‚
  â”‚           {condition}/run-{repIndex}.json  â”‚
  â”‚                                             â”‚
  â”‚ Atomic write: write to .tmp, then rename   â”‚
  â”‚ (prevents corruption from parallel workers)â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Phase 5: Report Generation

```
After all work items complete:

generateAndWriteReport(runDir)
    â”‚
    â”œâ”€â†’ loadResults(runDir)
    â”‚   â””â”€â†’ Read all result-{index}.json files
    â”‚       Group by taskId/condition
    â”‚
    â”œâ”€â†’ computeMetrics(results)
    â”‚   â”œâ”€â†’ taskPassRate: % of tasks with final_score >= 0.8
    â”‚   â”œâ”€â†’ hallucinationRate: % with >= 1 hallucination
    â”‚   â”œâ”€â†’ versionComplianceRate: % where ALL AST checks pass
    â”‚   â””â”€â†’ meanCombinedScore: average final_score
    â”‚
    â”œâ”€â†’ Aggregate by:
    â”‚   â”œâ”€â†’ Overall (all tasks, per condition)
    â”‚   â”œâ”€â†’ By category (bleeding_edge, etc.)
    â”‚   â”œâ”€â†’ By library (next, react, ai, trpc, zod)
    â”‚
    â”œâ”€â†’ Compute hallucination distribution
    â”‚
    â”œâ”€â†’ Extract per-task details
    â”‚   â””â”€â†’ Condition averages across reps
    â”‚
    â””â”€â†’ Write outputs:
        â”œâ”€â†’ report.json (structured data)
        â”œâ”€â†’ report.txt (human-readable ASCII table)
        â””â”€â†’ Display on stdout
```

---

## ğŸ“Š Result Visualization & Report Generation

### Structured Report Output (JSON)

File: `results/{timestamp}/report.json`

```typescript
interface Report {
  generatedAt: string                      // ISO timestamp
  resultsDir: string                       // Source directory path
  totalTasks: number                       // 40
  totalResults: number                     // e.g., 360 (40 Ã— 3 Ã— 3)
  conditions: string[]                     // ["baseline", "context7", "nia"]

  overall: ConditionMetrics[]              // Metrics per condition
  byCategory: {
    bleeding_edge: ConditionMetrics[]
    version_locked_write: ConditionMetrics[]
    version_locked_audit: ConditionMetrics[]
  }
  byLibrary: {
    next: ConditionMetrics[]
    react: ConditionMetrics[]
    ai: ConditionMetrics[]
    trpc: ConditionMetrics[]
    zod: ConditionMetrics[]
  }

  hallucinationDistribution: {
    baseline: HallucinationDistribution[]   // Per hallucination type
    context7: HallucinationDistribution[]
    nia: HallucinationDistribution[]
  }

  taskDetails: TaskDetail[]                // Per-task breakdown
}

interface ConditionMetrics {
  condition: string                        // "baseline", "context7", "nia"
  metrics: {
    taskPassRate: number                   // 0.0-1.0 (% tasks passing)
    hallucinationRate: number              // 0.0-1.0
    versionComplianceRate: number          // 0.0-1.0 (all AST checks pass)
    meanCombinedScore: number              // 0.0-1.0
    count: number                          // Sample size
  }
}

interface TaskDetail {
  taskId: string
  category: string
  library: string
  targetVersion: string
  conditions: {
    baseline: { avgFinalScore, avgTestScore, ... }
    context7: { ... }
    nia: { ... }
  }
}
```

### Human-Readable Report (ASCII Table)

File: `results/{timestamp}/report.txt`

Output Example:

```
================================================================
                     NIA-BENCH RESULTS v1.0
================================================================
 Metric                       Baseline    Context7        Nia
----------------------------------------------------------------
 Task Pass Rate                78.5%        82.1%       85.3%
 Hallucination Rate            12.3%         8.7%        5.2%
 Version Compliance Rate       85.0%        90.0%       93.0%
 Mean Combined Score            0.76         0.81        0.85
================================================================
 CATEGORY A: BLEEDING-EDGE TASKS
 Task Pass Rate                72.0%        80.0%       85.0%
 Hallucination Rate            20.0%        10.0%        5.0%
================================================================
 CATEGORY B1: VERSION-LOCKED WRITE
 Task Pass Rate                85.0%        90.0%       92.0%
 Version Compliance Rate       90.0%        95.0%       97.0%
...
```

### Metrics Explained

| Metric                      | Definition                             | Context                     |
| --------------------------- | -------------------------------------- | --------------------------- |
| **Task Pass Rate**          | % of tasks with final_score â‰¥ 0.8      | Overall success             |
| **Hallucination Rate**      | % of tasks with â‰¥1 hallucination       | False APIs, deprecated code |
| **Version Compliance Rate** | % where ALL AST checks pass            | Strict version correctness  |
| **Mean Combined Score**     | Weighted average: 0.6Ã—test + 0.4Ã—judge | Overall quality             |

---

## ğŸ¯ Task Categories

### Category A: Bleeding-Edge (14 tasks)

Features from latest library versions (likely post-training cutoff).

- **Next.js 16**: proxy.ts, enforced async, cache components (3)
- **React 19**: use() hook, useActionState, ref as prop (3)
- **AI SDK 5**: UIMessageStream, data parts, sync streamText (3)
- **tRPC 11**: transformer in link, SSE subscriptions, shorthand router (3)
- **Zod 4**: top-level validators, error API (2)

### Category B1: Version-Locked Write (14 tasks)

Write code correct for a _specific older version_.

- **Next.js 13**: Sync cookies/headers (3)
- **Next.js 14**: Direct params access (3)
- **Next.js 15**: middleware.ts (not proxy.ts) (1)
- **React 17**: useEffect+useState pattern (3)
- **React 18**: forwardRef required (1)
- **AI SDK 3**: await required, experimental_streamText (2)
- **tRPC 10**: Transformer at client level (1)
- **Zod 3**: Chained validators (1)

### Category B2: Version-Locked Audit (12 tasks)

Identify and fix version-incorrect code.

- Agents given code with bugs and must identify issues
- Suggest correct alternatives for target version

---

## ğŸ” AST Checks (Automated Testing)

Each task has a `test_spec.ast_checks[]` array with validation rules:

```typescript
// Example checks from nextjs-16-proxy-ts
[
  { type: "function_exported", name: "proxy" }, // âœ“ export function proxy() {}
  { type: "function_absent", name: "middleware" }, // âœ“ NOT export function middleware() {}
  { type: "call_exists", call: "config.matcher" }, // âœ“ export const config = { matcher: ... }
  { type: "property_absent", property: "runtime", inObject: "config" }, // âœ“ No runtime: 'edge'
];
```

### Check Types

- `import_exists`: Requires `import { X } from "module"`
- `import_absent`: Must NOT import something
- `module_import_absent`: Must NOT import entire module
- `function_exported`: Must export named function
- `function_absent`: Must NOT export named function
- `await_present`: Must `await` a specific call
- `await_absent`: Must NOT `await` something
- `call_exists`: Must call a specific function
- `call_absent`: Must NOT call something
- `directive_present`: Must have directive (e.g., `'use server'`)
- `property_location`: Property must be in specific object
- `async_function`: Function must be async
- `async_generator`: Function must be async generator
- `string_literal_check`: Check for literal strings in code

---

## ğŸ¤– LLM Judge Scoring

For tasks where automated AST checks alone aren't sufficient.

**Process:**

1. **Prompt Building** (prompt-template.ts):

   ```
   - Task description
   - Reference solution
   - Provided code
   - Rubric criteria (weighted)
   - Instruction: Score 0-1 per criterion
   ```

2. **API Call** (openrouter-client.ts):
   - Calls OpenRouter API with Claude Opus
   - Parses JSON response with criterion scores
   - Handles retries & timeouts

3. **Score Aggregation**:

   ```
   judgeScore = average(criterion_scores)
   finalScore = 0.6 Ã— testScore + 0.4 Ã— judgeScore
   ```

**Rubric Example** (nextjs-16-proxy-ts):

```json
{
  "criteria": [
    {
      "name": "proxy_filename",
      "weight": 0.25,
      "description": "File is proxy.ts, not middleware.ts"
    },
    {
      "name": "proxy_function_name",
      "weight": 0.25,
      "description": "Exports function proxy()"
    },
    {
      "name": "no_edge_runtime",
      "weight": 0.15,
      "description": "No runtime: 'edge' in config"
    },
    {
      "name": "correct_api_usage",
      "weight": 0.2,
      "description": "Correct NextResponse, cookies, redirects"
    },
    {
      "name": "no_hallucination",
      "weight": 0.15,
      "description": "No v15 patterns, no invented APIs"
    }
  ]
}
```

---

## ğŸ› Hallucination Classification

Maps failures to specific error categories:

```typescript
type HallucinationType =
  | "invented_method" // Method that doesn't exist (e.g., z.string().ip())
  | "wrong_parameter" // Wrong param name or type
  | "outdated_api" // Using old API from earlier version
  | "future_api" // Using API from newer version
  | "wrong_import_path" // Importing from wrong module
  | "version_mismatch"; // General version incompatibility
```

**Classification Logic:**

1. For each failed AST check â†’ map to hallucination type
2. Infer direction (older/newer) based on task metadata
3. Cross-reference with `common_hallucinations` hints
4. Aggregate into HallucinationResult

---

## ğŸ“¦ Key Dependencies

- **ts-morph** (v27.0.2): AST parsing and manipulation for code validation
- **zod** (v4.3.6): Runtime schema validation for task definitions
- **openai** (v6.18.0): OpenRouter API calls for LLM judge
- **bun**: Runtime and package manager
- **TypeScript** (v5): Type safety
- **Biome** (v2.3.14): Code formatting & linting

---

## ğŸš€ Running the Benchmark

### Basic Run

```bash
bun run src/index.ts
# Runs all 40 tasks Ã— 3 conditions Ã— 3 reps = 360 items
# Uses 1 worker (sequential)
# Results written to results/{timestamp}/
```

### With Options

```bash
# Run only Next.js 16 tasks with Nia condition, 2 reps, 4 workers
bun run src/index.ts \
  --library next \
  --task nextjs-16-proxy-ts \
  --condition nia \
  --reps 2 \
  --parallel 4

# Dry run: print execution plan without running
bun run src/index.ts --dry-run

# Skip judge evaluation (faster for iteration)
bun run src/index.ts --skip-judge

# Override model (use different Claude version)
bun run src/index.ts --model anthropic/claude-opus-4-1-20250805

# Generate report from existing results
bun run src/index.ts --report-only --output-dir results/{timestamp}
```

### CLI Flags

```
--category <cat>        Filter: bleeding_edge | version_locked_write | version_locked_audit
--library <lib>         Filter: next | react | ai | trpc | zod
--task <id>             Filter: single task ID
--condition <cond>      Filter: baseline | context7 | nia
--reps <n>              Repetitions per task (default: 3)
--parallel <n>          Worker threads (default: 1)
--skip-judge            Disable LLM judge (faster)
--keep-workdirs         Keep temp working directories (for debugging)
--timeout <ms>          Per-agent timeout (default: 300000)
--seed <n>              Random seed for work queue shuffle (reproducible order)
--dry-run               Print plan without executing
--eval-only             Re-run evaluation on existing results (partial support)
--report-only           Generate report from existing results
--output-dir <dir>      Results directory (default: results/)
--tasks-dir <dir>       Tasks directory (default: tasks/)
--model <id>            Model override (provider/model format)
```

---

## ğŸ“ Result File Structure

```
results/
â””â”€â”€ 2025-02-09T02-22-33-456Z/
    â”œâ”€â”€ run-meta.json
    â”‚   {
    â”‚     "startTime": "2025-02-09T02:22:33.456Z",
    â”‚     "endTime": "2025-02-09T03:15:44.123Z",
    â”‚     "totalTasks": 40,
    â”‚     "conditions": ["baseline", "context7", "nia"],
    â”‚     "reps": 3,
    â”‚     "parallel": 4,
    â”‚     "seed": 12345,
    â”‚     "status": "completed",
    â”‚     "completedItems": 360,
    â”‚     "totalItems": 360
    â”‚   }
    â”œâ”€â”€ report.json          # Structured report (for parsing)
    â”œâ”€â”€ report.txt           # Human-readable ASCII table
    â”‚
    â”œâ”€â”€ nextjs-16-proxy-ts/
    â”‚   â”œâ”€â”€ baseline/
    â”‚   â”‚   â”œâ”€â”€ run-0.json   # Rep 0 result
    â”‚   â”‚   â”œâ”€â”€ run-1.json   # Rep 1 result
    â”‚   â”‚   â””â”€â”€ run-2.json   # Rep 2 result
    â”‚   â”œâ”€â”€ context7/
    â”‚   â”‚   â””â”€â”€ run-*.json
    â”‚   â””â”€â”€ nia/
    â”‚       â””â”€â”€ run-*.json
    â”‚
    â”œâ”€â”€ nextjs-16-enforced-async/
    â”‚   â””â”€â”€ ...
    â”‚
    â””â”€â”€ [38 more task directories]
```

### Individual Result File (`run-X.json`)

```typescript
{
  taskId: "nextjs-16-proxy-ts",
  condition: "nia",
  runIndex: 0,
  testScore: 0.95,                    // % AST checks passed
  judgeScore: 0.88,                   // Judge's evaluation
  finalScore: 0.922,                  // 0.6Ã—0.95 + 0.4Ã—0.88
  astResults: [                       // One per check
    {
      check: { type: "function_exported", name: "proxy" },
      passed: true,
      message: "Found function export: proxy"
    },
    ...
  ],
  typeCheckResult: {                  // If enabled
    passed: true,
    errors: []
  },
  judgeResult: {
    criterion_scores: {
      proxy_filename: 1.0,
      proxy_function_name: 1.0,
      no_edge_runtime: 1.0,
      correct_api_usage: 0.75,
      no_hallucination: 0.5
    },
    explanations: { ... }
  },
  hallucinations: {
    types: ["wrong_parameter"],       // Classification
    details: [
      {
        type: "wrong_parameter",
        evidence: "...",
        description: "..."
      }
    ]
  },
  extractedFiles: {
    "proxy.ts": "export function proxy(request) { ... }"
  }
}
```

---

## ğŸ”§ Key Classes & Functions

### Orchestrator (orchestrator.ts)

- `parseCliArgs(argv)`: Parse command-line arguments
- `generateWorkQueue(taskIds, conditions, reps)`: Create work items
- `runBenchmark(config)`: Main entry point
- `ProgressLogger`: Tracks completion + ETA
- `AsyncSemaphore`: Concurrency control

### Agent (agent.ts)

- `runAgent(task, condition, repIndex)`: Execute OpenCode
- `checkOpencodeBinary()`: Verify opencode CLI is installed
- `extractCodeFromOutput(rawOutput)`: Parse NDJSON events

### Evaluator (evaluator.ts)

- `evaluateCode(task, extractedFiles, ...)`: Full evaluation pipeline
- `runAstChecks(code, checks)`: Validate with AST
- `runTypeCheck(code, envPath)`: TypeScript checking

### Reporter (reporter.ts)

- `loadResults(runDir)`: Read all result files
- `computeMetrics(results)`: Aggregate statistics
- `formatReportText(report)`: Generate ASCII table
- `generateAndWriteReport(runDir)`: Write JSON + TXT outputs

### Hallucination Classifier (judge/hallucination-classifier.ts)

- `classifyHallucinations(task, astResults, judgeResult)`: Map failures to types

### Rubric Scorer (judge/rubric-scorer.ts)

- `scoreWithRubric(code, task, condition)`: LLM judge evaluation
- `calculateJudgeScore(responses)`: Average criterion scores

---

## ğŸ“Š Data Flow Summary

```
Input: User CLI args
  â”‚
  â”œâ”€â†’ Load tasks (validate with Zod)
  â”œâ”€â†’ Generate work queue (shuffle with seed)
  â”‚
  â”œâ”€â†’ For each work item [taskId, condition, rep]:
  â”‚   â”‚
  â”‚   â”œâ”€â†’ Run Agent
  â”‚   â”‚   â””â”€â†’ Execute opencode CLI
  â”‚   â”‚   â””â”€â†’ Extract code files from NDJSON stream
  â”‚   â”‚
  â”‚   â”œâ”€â†’ Evaluate Code
  â”‚   â”‚   â”œâ”€â†’ AST Checks (ts-morph)
  â”‚   â”‚   â”œâ”€â†’ Type Check (tsc in version-specific env)
  â”‚   â”‚   â”œâ”€â†’ Classify Hallucinations
  â”‚   â”‚   â””â”€â†’ Judge Scoring (OpenRouter API)
  â”‚   â”‚
  â”‚   â””â”€â†’ Store Result (atomic write to JSON)
  â”‚
  â””â”€â†’ Generate Report
      â”œâ”€â†’ Load all results
      â”œâ”€â†’ Compute metrics (pass rate, compliance, etc.)
      â”œâ”€â†’ Aggregate by category/library/condition
      â””â”€â†’ Write report.json + report.txt + stdout

Output: Results directory with JSON + text reports
```

---

## Key Concepts

### Conditions

- **Baseline**: Pure LLM capability (no context tools)
- **Context7**: Context augmentation tool #1
- **Nia**: Context augmentation tool #2 (full toolset)
  â†’ Measures how much context tools improve accuracy

### Categories

- **Bleeding-Edge (A)**: Latest features (post-training cutoff)
  - Measures: Can context tools help with unknown features?
- **Version-Locked Write (B1)**: Code for specific old version
  - Measures: Can agents stick to old APIs when required?
- **Version-Locked Audit (B2)**: Identify version bugs in given code
  - Measures: Can agents recognize and fix version issues?

### Scoring

- **Test Score**: % of automated AST checks passing (0-1)
- **Judge Score**: LLM evaluation of rubric criteria (0-1)
- **Final Score**: 60% test + 40% judge (0-1)
- **Pass Threshold**: finalScore â‰¥ 0.8 for task to count as "passed"
