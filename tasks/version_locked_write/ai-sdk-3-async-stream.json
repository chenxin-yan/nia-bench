{
	"id": "ai-sdk-3-async-stream",
	"category": "version_locked_write",
	"library": "ai",
	"target_version": "3.4.0",
	"prompt": "This project uses **Vercel AI SDK v3**. Create a Next.js Route Handler that streams a chat response. Use `experimental_streamText` with the proper v3 async pattern and `toAIStreamResponse()`. Use `openai('gpt-3.5-turbo')` as the model.",
	"context": {
		"package_json": "{\n  \"dependencies\": {\n    \"ai\": \"3.4.33\",\n    \"@ai-sdk/openai\": \"0.0.72\"\n  }\n}"
	},
	"reference_solution": "import { experimental_streamText } from 'ai';\nimport { openai } from '@ai-sdk/openai';\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n\n  const result = await experimental_streamText({\n    model: openai('gpt-3.5-turbo'),\n    messages,\n  });\n\n  return result.toAIStreamResponse();\n}",
	"test_spec": {
		"ast_checks": [
			{
				"type": "import_exists",
				"name": "experimental_streamText",
				"from": "ai"
			},
			{
				"type": "await_present",
				"call": "experimental_streamText"
			},
			{
				"type": "call_exists",
				"call": "result.toAIStreamResponse"
			},
			{
				"type": "import_absent",
				"name": "streamText",
				"from": "ai"
			},
			{
				"type": "call_absent",
				"call": "result.toDataStreamResponse"
			}
		],
		"type_check": false
	},
	"rubric": {
		"criteria": [
			{
				"name": "experimental_prefix",
				"weight": 0.3,
				"description": "Uses `experimental_streamText`"
			},
			{
				"name": "await_required",
				"weight": 0.3,
				"description": "Awaits the stream call"
			},
			{
				"name": "ai_stream_response",
				"weight": 0.25,
				"description": "Uses `toAIStreamResponse()`"
			},
			{
				"name": "no_hallucination",
				"weight": 0.15,
				"description": "No v4/v5 patterns"
			}
		]
	},
	"common_hallucinations": [
		"Using `streamText` without `experimental_` prefix (v4+)",
		"Calling without `await` (v4+ sync pattern)",
		"Using `toDataStreamResponse()` (v4)"
	]
}
